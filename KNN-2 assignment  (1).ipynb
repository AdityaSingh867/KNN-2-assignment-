{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca922c2-cfe2-44be-9b7b-2f1e71183306",
   "metadata": {},
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance\n",
    "metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb1b766-4b28-4e00-845e-f365e6534b0f",
   "metadata": {},
   "source": [
    "Enclidean distance is a stright line distance brtween any two points.\n",
    "\n",
    "Manhattan distance is a actual path distance of any to points like this :\n",
    "\n",
    "Let a car travle from A to B and B to C so the distance between A and C is (A+B) + (B+C) in manhattan distance rule "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26521337-704f-41c7-b24c-29ff955de5de",
   "metadata": {},
   "source": [
    "                               ' C\n",
    "                              ''\n",
    "                            '  '\n",
    "                          '    '\n",
    "                        '      '\n",
    "                      '        '\n",
    "                    '          '\n",
    "                  '            '\n",
    "                '              '\n",
    "              '                '\n",
    "            '                  '\n",
    "          '                    '\n",
    "        '                      '\n",
    "      '                        '\n",
    "    ------------------------------B\n",
    "   A                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e3cca-9e95-49d1-9035-92c3d57dcf7a",
   "metadata": {},
   "source": [
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "used to determine the optimal k value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b143f7-e59f-4099-a681-4aad87eab995",
   "metadata": {},
   "source": [
    "cross-validation tactics can help you choose the optimal k for your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9cdcf4-9b43-41ed-84c4-fb47b12e45e3",
   "metadata": {},
   "source": [
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In\n",
    "what situations might you choose one distance metric over the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096ae92-968e-4df8-84c8-594bdb8dd9b4",
   "metadata": {},
   "source": [
    "the KNN to classify test examples with the highest precision, recall and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14fcb85-21dc-4905-9237-28051257b6f0",
   "metadata": {},
   "source": [
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142c2c9-6702-4d21-a0e5-dad92a86a066",
   "metadata": {},
   "source": [
    "number of nearest neighbors (k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb7d1c-4bd6-46ba-9da2-cfe4e2ba3c07",
   "metadata": {},
   "source": [
    "A smaller value of k can result in a more flexible model that is more sensitive to noise in the data, while a larger value of k can result in a smoother model that is less sensitive to noise but may not capture more complex patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff629f7b-9896-40d8-8d66-8571b06b9bf1",
   "metadata": {},
   "source": [
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What\n",
    "techniques can be used to optimize the size of the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4e271-ba3f-4cd7-ad15-62c5e26e682c",
   "metadata": {},
   "source": [
    "A large training set improves the robustness of our model against omission noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736bba5-805d-411f-b56e-d2f0ad8400b3",
   "metadata": {},
   "source": [
    "k-fold cross-validation or leave-one-out cross-validation, both of which give you more thorough model testing but not at the cost of reducing the size of your kNN neighbor population.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa39e892-dbf4-49aa-90fb-13722e57f288",
   "metadata": {},
   "source": [
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you\n",
    "overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c8bca-e275-4115-9cf1-12b37708df8f",
   "metadata": {},
   "source": [
    "-\n",
    "Accuracy depends on the quality of the data.\n",
    "-\n",
    "With large data, the prediction stage might be slow.\n",
    "-\n",
    "Sensitive to the scale of the data and irrelevant features.\n",
    "-\n",
    "Require high memory â€“ need to store all of the training data.\n",
    "-\n",
    "Given that it stores all of the training, it can be computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ec7419-b5a6-4cc9-b035-e152199ed28f",
   "metadata": {},
   "source": [
    "One way to overcome the sensitivity to the scale of the input features is to normalize or standardize "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
